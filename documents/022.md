# elasticsearch-analysis-ansj自定义分词器

## 1. 配置词典

配置`${ES_HOME}/config/elasticsearch-analysis-ansj/ansj.cfg.yml`文件，内容如下：

```yml
# 全局变量配置方式一
ansj:
  #默认参数配置
  isNameRecognition: true #开启姓名识别
  isNumRecognition: true #开启数字识别
  isQuantifierRecognition: true #是否数字和量词合并
  isRealName: false #是否保留真实词语,建议保留false

  #用户自定词典配置
  dic: default.dic #也可以写成 file//default.dic , 如果未配置dic,则此词典默认加载
  # http方式加载
  dic_1: http://xxx/xx.dic
  # jar中文件加载
  dic_2: jar://org.ansj.dic.DicReader|/dic2.dic
  # 从数据库中加载
  dic_3: jdbc://jdbc:mysql://xxxx:3306/ttt?useUnicode=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull|username|password|select name as name,nature,freq from dic where type=1
  # 从自定义类中加载,YourClas  extends PathToStream
  dic_4: class://xxx.xxx.YourClas|ohterparam

  #过滤词典配置
  #stop: http,file,jar,class,jdbc 都支持

  #歧义词典配置
  #ambiguity: http,file,jar,class,jdbc 都支持

  #同义词词典配置
  #synonyms: http,file,jar,class,jdbc 都支持
```

## 2. 创建索引时指定分词器

创建索引时设置自定义的分词器，创建索引的接口的参数如下：

```json
{
    "settings": {
        "analysis": {
            "tokenizer": {
                "test_index_tokenizer": {
                    "type": "index_ansj",
                    "dic": "dic_1"
                },
                "test_query_tokenizer": {
                    "type": "query_ansj",
                    "dic": "dic_2,dic_3",
                    "stop": "stop",
                    "ambiguity": "ambiguity",
                    "synonyms": "synonyms",
                    "isNameRecognition": true,
                    "isNumRecognition": true,
                    "isQuantifierRecognition": true,
                    "isRealName": false
                }
            },
            "analyzer": {
                "test_index_ansj": {
                    "type": "custom",
                    "tokenizer": "test_index_tokenizer"
                },
                "test_query_ansj": {
                    "type": "custom",
                    "tokenizer": "test_query_tokenizer"
                }
            }
        }
    },
    "mappings": {
        "document": {
            "properties": {
                "test": {
                    "type": "text",
                    "analyzer": "test_index_ansj",
                    "search_analyzer": "test_query_ansj"
                }
            }
        }
    }
}
```

首先要在`settings.analysis.tokenizer`中定义tokenizer，type的值为elasticsearch-analysis-ansj中已有的分词器，dic、stop、ambiguity、synonyms的值为[1. 配置词典](#1-配置词典)中的dic、dic_1等词典，isNameRecognition等参数也可以配置，如果不配置则使用[1. 配置词典](#1-配置词典)中的默认配置

然后在`settings.analysis.analyzer`中定义analyzer，type的值为custom，tokenizer的值为`settings.analysis.tokenizer`中定义的tokenizer

最后在`mappings.${文档名称}.properties.${字段名称}`中将analyzer和search_analyzer的值指定为`settings.analysis.analyzer`中定义的analyzer
